{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2f60625-83ef-4d33-af46-d927f181d4f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1 documents into 40 chunks.\n",
      "Reentrancy Description: A reentrancy attack exploits the vulnerability in smart contracts when a function makes an external call to another contract before updating its own state. This allows the external contract, possibly malicious, to reenter the original function and repeat certain actions, like withdrawals, using the same state. Through such attacks, an attacker can possibly drain all the funds from a contract. • A simple example of a reentrancy attack is a contract that allows users to deposit funds and then withdraw those funds later. Suppose the contract does not properly check for reentrancy. In that case, an attacker could call the deposit function multiple times in a row before calling the withdraw function, effectively stealing funds from the contract. • One way to prevent reentrancy attacks is to use a mutex, or mutual exclusion, lock to prevent multiple calls to the same function from occurring at the same time. Another way is to use a guard condition, where a flag is\n",
      "{'source': 'data\\\\vulnhunt_doc.md', 'start_index': 46}\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "DATA_PATH=\"data\"\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "os.environ['PINECONE_API_KEY'] = ''\n",
    "api_key = os.environ[\"PINECONE_API_KEY\"]\n",
    "OPENAI_API_KEY=os.environ[\"OPENAI_API_KEY\"]\n",
    "pc = Pinecone(api_key=api_key)\n",
    "\n",
    "\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "\n",
    "\n",
    "# def load_documents():\n",
    "loader = DirectoryLoader(DATA_PATH, glob=\"*md\")\n",
    "documents = loader.load()\n",
    "    # return documents\n",
    "\n",
    "# def split_text(documents: list[Document]):\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=500,\n",
    "        length_function=len,\n",
    "        add_start_index=True,\n",
    "    )\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "print(f\"Split {len(documents)} documents into {len(chunks)} chunks.\")\n",
    "\n",
    "document = chunks[1]\n",
    "print(document.page_content)\n",
    "print(document.metadata)\n",
    "\n",
    "    # return chunks \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5f7db61-ad18-47ce-9419-f71a0cf99174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully initialize index\n",
      "successfully add records\n"
     ]
    }
   ],
   "source": [
    "index_name = \"vulnhunt-gpt\"\n",
    "\n",
    "# def create_index(docs):\n",
    "existing_indexes = [index_info[\"name\"] for index_info in pc.list_indexes()]\n",
    "if index_name not in existing_indexes:\n",
    "    # dimensions are for text-embedding-ada-002\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=1536,\n",
    "        metric=\"euclidean\",\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"), \n",
    "    )   \n",
    "    index = pc.Index(index_name)\n",
    "    print(\"successfully initialize index\")\n",
    "# add records/vectors into index\n",
    "vectorstore_from_docs = PineconeVectorStore.from_documents(\n",
    "    chunks,\n",
    "    index_name=index_name,\n",
    "    embedding=embeddings\n",
    ")\n",
    "print(\"successfully add records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34e87efc-620e-4434-8a9b-37da19ee1132",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vectorstore_from_docs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mvectorstore_from_docs\u001b[49m\u001b[38;5;241m.\u001b[39msimilarity_search(\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhat is overflow\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      3\u001b[0m k \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m      4\u001b[0m )\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results: \n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(res, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m -----------\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'vectorstore_from_docs' is not defined"
     ]
    }
   ],
   "source": [
    "results = vectorstore_from_docs.similarity_search(\n",
    "\"what is overflow\",\n",
    "k = 2\n",
    ")\n",
    "for res in results: \n",
    "    print(res, \"\\n -----------\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84ce34a7-39f6-44ac-931b-a3f8d77654c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI  \n",
    "from langchain.chains import RetrievalQAWithSourcesChain  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cc82bff-891b-4c2f-848e-6b6f8625185d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'what is the vulnerability in this code, and give me the remediation of the vulnerability pragma solidity ^0.4.15; \\n\\ncontract Main { \\n    uint private sellerBalance=0; \\n\\n    function add(uint value) returns (bool){ \\n        sellerBalance += value; // possible overflow \\n\\n        // possible auditor assert \\n        // assert(sellerBalance >= value); \\n    } \\n\\n    function safe_add(uint value) returns (bool){ \\n        require(value + sellerBalance >= sellerBalance); \\n        sellerBalance += value; \\n    }   \\n}',\n",
       " 'answer': 'The vulnerability in the code is a possible overflow in the `add` function. The remediation for this vulnerability is to use the `safe_add` function that includes a require statement to prevent overflow.\\n',\n",
       " 'sources': 'data\\\\vulnhunt_doc.md'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"what is the vulnerability in this code, and give me the remediation of the vulnerability \\\n",
    "pragma solidity ^0.4.15; \\n\\n\\\n",
    "contract Main { \\n\\\n",
    "    uint private sellerBalance=0; \\n\\n\\\n",
    "    function add(uint value) returns (bool){ \\n\\\n",
    "        sellerBalance += value; // possible overflow \\n\\n\\\n",
    "        // possible auditor assert \\n\\\n",
    "        // assert(sellerBalance >= value); \\n\\\n",
    "    } \\n\\n\\\n",
    "    function safe_add(uint value) returns (bool){ \\n\\\n",
    "        require(value + sellerBalance >= sellerBalance); \\n\\\n",
    "        sellerBalance += value; \\n\\\n",
    "    }   \\n\\\n",
    "}\"\n",
    "llm = ChatOpenAI(  \n",
    "    openai_api_key=OPENAI_API_KEY,  \n",
    "    model_name='gpt-3.5-turbo',  \n",
    "    temperature=0.0, \n",
    ")  \n",
    "qa = RetrievalQAWithSourcesChain.from_chain_type(  \n",
    "    llm=llm,  \n",
    "    chain_type=\"stuff\",  \n",
    "    retriever=vectorstore_from_docs.as_retriever()  \n",
    ")  \n",
    "qa.invoke(query)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a14a1a9-7072-4da8-8d13-5bba542df97d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47dd8379-1b02-4a80-b53b-dd0fa9c5e94b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de7e1b1-be19-4e56-b5e2-2058ea1cfc3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
